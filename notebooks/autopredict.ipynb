{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88ff6ccc"
   },
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "!pip install seaborn\n",
    "!pip install pandas\n",
    "!pip install plotly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "from io import StringIO\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80633af2",
    "outputId": "32420c51-b850-4b12-cd53-b1b232fe839e"
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "\n",
    "df = pd.read_csv(\"vehicle_maintenance_data.csv\")\n",
    "\n",
    "# Confirm dataset loaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52859658"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28e3ac83",
    "outputId": "13196839-4fba-46f7-97c9-90a844c2c4e6"
   },
   "outputs": [],
   "source": [
    "# Dataset details and summary statistics\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "# Categorical Summary Statistics\n",
    "print(f'Categorical Summary Statistics \\ndf.describe(include= object).T\\n')\n",
    "\n",
    "# Numerical Summary Statistics\n",
    "print(f'Numerical Summary Statistics \\ndf.describe(include= np.number).T\\n')\n",
    "\n",
    "# Isolate numerical variables\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "# Isolate categorical variables\n",
    "categorical_df = df.select_dtypes(include=object)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57YVjy9ytlpg",
    "outputId": "62f13811-a846-41f2-b0b1-f7e563bc6868"
   },
   "outputs": [],
   "source": [
    "# Confirm outliers for Numerical variables\n",
    "def highlight_outliers(s):\n",
    "    '''\n",
    "    Highlight values that are outside of 3 standard deviations from the mean.\n",
    "    '''\n",
    "    is_outlier = (np.abs(s - s.mean()) > 3 * s.std())\n",
    "    return ['background-color: red' if v else '' for v in is_outlier]\n",
    "\n",
    "# Apply function\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "styled_df = numeric_df.describe().T.style.apply(highlight_outliers)\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSVBmzAxv7ZD"
   },
   "source": [
    "# **Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTdvCn6ouLrP",
    "outputId": "f992b17e-d1b2-43b3-a798-800e6eb6a0b6"
   },
   "outputs": [],
   "source": [
    "# Distribution of numeric variables\n",
    "\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# isolating numeric variables\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "for column in numeric_df.columns:\n",
    "    # Summary statistics\n",
    "    print(f\"Summary Statistics for {column}:\\n{numeric_df[column].describe()}\\n\")\n",
    "\n",
    "    # Create subplots\n",
    "    fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(f\"Histogram of {column}\", f\"Box Plot of {column}\"))\n",
    "\n",
    "    # Histogram\n",
    "    fig.add_trace(go.Histogram(x=numeric_df[column]), row=1, col=1)\n",
    "\n",
    "    # Box plot\n",
    "    fig.add_trace(go.Box(y=numeric_df[column]), row=1, col=2)\n",
    "\n",
    "    fig.update_layout(height=600, width=1000, title_text=f\"Plots for {column}\", showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1veM_F0BuzVN",
    "outputId": "e888f9e5-8eb2-40ac-cd35-ef3d595eabfc"
   },
   "outputs": [],
   "source": [
    "# Distribution of Categorical variables\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "categorical_df = df.select_dtypes(include=object)\n",
    "\n",
    "for column in categorical_df.columns:\n",
    "    # Value counts and percentages\n",
    "    value_counts = categorical_df[column].value_counts()\n",
    "    percentages = (value_counts / len(categorical_df) * 100).round(2)\n",
    "    print(f\"Value Counts and Percentages for {column}:\\n{value_counts}\\n{percentages}\\n\")\n",
    "\n",
    "    # Bar plot\n",
    "    fig = px.bar(\n",
    "        x=value_counts.index,\n",
    "        y=value_counts.values,\n",
    "        title=f\"Bar Plot of {column}\",\n",
    "        labels={\"x\": column, \"y\": \"Count\"},\n",
    "        text=percentages.astype(str) + \"%\",  # Display percentages on bars\n",
    "    )\n",
    "    fig.update_traces(textposition=\"outside\")  # Position percentages outside bars\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1WWFkBAzpuB"
   },
   "source": [
    "# **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCTZ9fz4vlh7",
    "outputId": "f64e9d5f-c8a7-4797-b655-23ba757d51b4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('vehicle_maintenance_data.csv')  # Uncomment and load your data\n",
    "\n",
    "# Calculate correlation matrix, considering only numeric columns\n",
    "correlation_matrix = df.corr(numeric_only=True)  # Added numeric_only=True\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))  # Adjust figure size if needed\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Vehicle Maintenance Dataset\")\n",
    "plt.show()\n",
    "\n",
    "# Find top 5 and bottom 5 correlated feature pairs\n",
    "correlation_pairs = correlation_matrix.unstack().reset_index()\n",
    "correlation_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "correlation_pairs = correlation_pairs[correlation_pairs['Feature 1'] != correlation_pairs['Feature 2']]  # Remove self-correlation\n",
    "correlation_pairs = correlation_pairs.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Top 5 correlations\n",
    "top_5 = correlation_pairs.head(5)\n",
    "# Bottom 5 correlations\n",
    "bottom_5 = correlation_pairs.tail(5)\n",
    "\n",
    "# Combine top and bottom correlations\n",
    "correlation_summary = pd.concat([top_5, bottom_5])\n",
    "\n",
    "# Create Plotly table\n",
    "table = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(correlation_summary.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[correlation_summary['Feature 1'], correlation_summary['Feature 2'], correlation_summary['Correlation']],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "table.update_layout(title='Top 5 and Bottom 5 Correlations in Vehicle Maintenance Dataset')\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL9Qn_x4wtwE",
    "outputId": "dc7fc5d0-732d-4f3c-cdc5-a0154f10d39c"
   },
   "outputs": [],
   "source": [
    "!pip install researchpy\n",
    "import researchpy as rp\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Isolate the categorical variables\n",
    "categorical_df = df.select_dtypes(include=['object', 'category'])  # Select only categorical columns\n",
    "\n",
    "# Create an empty list to store the results of chi-square and Cramer's V calculations\n",
    "results = []\n",
    "\n",
    "# Iterate through pairs of categorical variables\n",
    "for col1 in categorical_df.columns:\n",
    "    for col2 in categorical_df.columns:\n",
    "        if col1 != col2:  # Avoid comparing a column with itself\n",
    "            # Create a cross-tabulation of the two variables\n",
    "            crosstab = pd.crosstab(df[col1], df[col2])\n",
    "\n",
    "            # Perform the chi-square test on the crosstab\n",
    "            chi2, p, dof, expected = chi2_contingency(crosstab)\n",
    "\n",
    "            # Calculate Cramer's V for association strength\n",
    "            n = crosstab.sum().sum()  # Total number of observations\n",
    "            cramer_v = (chi2 / (n * (min(crosstab.shape) - 1))) ** 0.5\n",
    "\n",
    "            # Append the results to the list\n",
    "            results.append({\n",
    "                'col1': col1,\n",
    "                'col2': col2,\n",
    "                'chi-square': chi2,\n",
    "                'p-value': p,\n",
    "                'cramer_v': cramer_v\n",
    "            })\n",
    "\n",
    "# Convert the results into a DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Create subplots for heatmaps and annotations for each pair of categorical variables\n",
    "fig = make_subplots(\n",
    "    rows=len(results_df),\n",
    "    cols=1,\n",
    "    subplot_titles=[f\"{row['col1']} vs {row['col2']}\" for _, row in results_df.iterrows()]\n",
    ")\n",
    "\n",
    "# Add heatmaps and annotations to each subplot\n",
    "for i, row in results_df.iterrows():\n",
    "    # Generate the crosstab for the current pair of variables\n",
    "    crosstab = pd.crosstab(df[row['col1']], df[row['col2']])\n",
    "\n",
    "    # Create a heatmap for the crosstab\n",
    "    heatmap = go.Heatmap(\n",
    "        z=crosstab.values,\n",
    "        x=crosstab.columns,\n",
    "        y=crosstab.index,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Count')\n",
    "    )\n",
    "\n",
    "    fig.add_trace(heatmap, row=i + 1, col=1)\n",
    "\n",
    "    # Add annotations for chi-square test results and Cramer's V\n",
    "    fig.add_annotation(\n",
    "        text=f\"Chi-square: {row['chi-square']:.3f}<br>P-value: {row['p-value']:.3f}<br>Cramer's V: {row['cramer_v']:.3f}\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.05, y=0.95 - i * 0.1,  # Adjust position for each subplot\n",
    "        showarrow=False\n",
    "    )\n",
    "\n",
    "# Update the layout and display the figure\n",
    "fig.update_layout(\n",
    "    height=400 * len(results_df),  # Set the height dynamically based on the number of subplots\n",
    "    width=800,\n",
    "    title_text=\"Chi-Square Test Results Between Categorical Variables\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CWnBmcv4qNK"
   },
   "source": [
    "# **Chi-Squared Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzEBdwpf0ETA",
    "outputId": "0cb4eb9f-07dc-4ef5-e74b-351f568dac7b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Function to map Need_Maintenance\n",
    "def map_maintenance(dataframe):\n",
    "    return dataframe['Need_Maintenance'].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('vehicle_maintenance_data.csv') \n",
    "\n",
    "# First Analysis: Chi-Square Tests for Tire and Brake Conditions\n",
    "\n",
    "# Create a copy of the original DataFrame for the first analysis\n",
    "df_analysis_1 = df.copy()\n",
    "df_analysis_1['Need_Maintenance'] = map_maintenance(df_analysis_1)\n",
    "\n",
    "# Focus on the relevant columns for the first analysis\n",
    "relevant_columns = ['Tire_Condition', 'Brake_Condition', 'Need_Maintenance']\n",
    "df_filtered = df_analysis_1[relevant_columns]\n",
    "\n",
    "# Check for missing values in relevant columns\n",
    "missing_values = df_filtered.isnull().sum()\n",
    "print(\"Missing Values in Analysis 1:\\n\", missing_values)\n",
    "\n",
    "# Drop rows with any missing values in the relevant columns\n",
    "df_filtered = df_filtered.dropna()\n",
    "\n",
    "# Check if the filtered DataFrame is empty\n",
    "if df_filtered.empty:\n",
    "    print(\"Filtered DataFrame is empty after dropping missing values in Analysis 1.\")\n",
    "else:\n",
    "    # Chi-Square Test for Tire_Condition and Need_Maintenance\n",
    "    tire_crosstab = pd.crosstab(df_filtered['Tire_Condition'], df_filtered['Need_Maintenance'])\n",
    "    chi2_tire, p_tire, dof_tire, expected_tire = chi2_contingency(tire_crosstab)\n",
    "\n",
    "    # Chi-Square Test for Brake_Condition and Need_Maintenance\n",
    "    brake_crosstab = pd.crosstab(df_filtered['Brake_Condition'], df_filtered['Need_Maintenance'])\n",
    "    chi2_brake, p_brake, dof_brake, expected_brake = chi2_contingency(brake_crosstab)\n",
    "\n",
    "    # Output the results of the chi-square tests\n",
    "    print(f\"Tire Condition vs Need Maintenance: Chi-square = {chi2_tire:.3f}, p-value = {p_tire:.3f}\")\n",
    "    print(f\"Brake Condition vs Need Maintenance: Chi-square = {chi2_brake:.3f}, p-value = {p_brake:.3f}\")\n",
    "\n",
    "    # Visualization 1: Tire Condition vs Need Maintenance\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x='Tire_Condition', hue='Need_Maintenance', data=df_filtered, palette='viridis')\n",
    "    plt.title('Influence of Tire Condition on Maintenance Needs')\n",
    "    plt.xlabel('Tire Condition')\n",
    "    plt.ylabel('Count of Vehicles')\n",
    "    plt.legend(title='Need Maintenance', loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization 2: Brake Condition vs Need Maintenance\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x='Brake_Condition', hue='Need_Maintenance', data=df_filtered, palette='plasma')\n",
    "    plt.title('Influence of Brake Condition on Maintenance Needs')\n",
    "    plt.xlabel('Brake Condition')\n",
    "    plt.ylabel('Count of Vehicles')\n",
    "    plt.legend(title='Need Maintenance', loc='upper right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwfCuKIh5U__",
    "outputId": "4b8c78fa-4437-4e8e-d9b6-5a278d24d587"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             roc_curve, roc_auc_score, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('vehicle_maintenance_data.csv') \n",
    "\n",
    "# Check for any missing values in the original column\n",
    "print(\"Initial unique values in 'Need_Maintenance':\", df['Need_Maintenance'].unique())\n",
    "\n",
    "# Impute 'Need_Maintenance' to be categorical (1 = Yes, 0 = No)\n",
    "df['Need_Maintenance'] = df['Need_Maintenance'].map({1: 1, 0: 0})  # Keep it numeric\n",
    "\n",
    "# Check for any NaN values after mapping\n",
    "print(\"Unique values after mapping:\", df['Need_Maintenance'].unique())\n",
    "if df['Need_Maintenance'].isnull().any():\n",
    "    print(\"NaN values found in 'Need_Maintenance' after mapping, check your data.\")\n",
    "\n",
    "# Check for and drop any rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['Need_Maintenance'])\n",
    "y = df['Need_Maintenance']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Check unique values in y_test and y_pred\n",
    "print(\"Unique values in y_test:\", np.unique(y_test))\n",
    "print(\"Unique values in y_pred:\", np.unique(y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "labels = np.unique(y_test)  # Use unique values from y_test for the labels\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "# ROC Curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Feature Importances\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plotting in a 2x2 subplot layout\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)  # Adjust space between subplots\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_display.plot(ax=axs[0, 0], cmap='Blues', values_format='d')\n",
    "axs[0, 0].set_title('Confusion Matrix')\n",
    "\n",
    "# ROC Curve\n",
    "axs[0, 1].plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "axs[0, 1].plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "axs[0, 1].set_xlabel('False Positive Rate')\n",
    "axs[0, 1].set_ylabel('True Positive Rate')\n",
    "axs[0, 1].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0, 1].legend(loc='lower right')\n",
    "\n",
    "# Feature Importances\n",
    "axs[1, 0].barh(range(X.shape[1]), importances[indices], align='center')\n",
    "axs[1, 0].set_yticks(range(X.shape[1]))\n",
    "axs[1, 0].set_yticklabels(X.columns[indices])\n",
    "axs[1, 0].invert_yaxis()  # Inverse the y-axis to have the most important features at the top\n",
    "axs[1, 0].set_xlabel('Feature Importance')\n",
    "axs[1, 0].set_title('Feature Importances')\n",
    "\n",
    "# Displaying Metrics in a Table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "# Creating a table for metrics\n",
    "axs[1, 1].axis('tight')\n",
    "axs[1, 1].axis('off')\n",
    "axs[1, 1].table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center')\n",
    "axs[1, 1].set_title('Model Performance Metrics')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uzn1vCg5sLt"
   },
   "source": [
    "# **XGBoost Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCnKDdbh5p1-",
    "outputId": "c7bd7a95-83f9-466f-f1bf-35037f488862"
   },
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install xgboost shap\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(label_encoders, 'encoders.pkl')  # Save the label encoders separately\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             roc_curve, roc_auc_score, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shap  # For SHAP explanations\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"vehicle_maintenance_data.csv\")  # Update with actual data path\n",
    "\n",
    "# Assuming df has a target column 'Need_Maintenance' and several feature columns\n",
    "df['Need_Maintenance'] = df['Need_Maintenance'].map({1: 1, 0: 0})\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['Need_Maintenance'])\n",
    "y = df['Need_Maintenance']\n",
    "print(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(importance_df)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "print(y_pred)\n",
    "\n",
    "# ROC Curve and AUC calculation\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))  # Create a 2x2 subplot layout\n",
    "\n",
    "# Confusion Matrix\n",
    "labels = np.unique(y_test)  # Use unique values from y_test for the labels\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "cm_display.plot(ax=axs[0, 0], cmap='Blues', values_format='d')\n",
    "axs[0, 0].set_title('Confusion Matrix')\n",
    "\n",
    "# ROC Curve\n",
    "axs[0, 1].plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "axs[0, 1].plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "axs[0, 1].set_xlabel('False Positive Rate')\n",
    "axs[0, 1].set_ylabel('True Positive Rate')\n",
    "axs[0, 1].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0, 1].legend(loc='lower right')\n",
    "\n",
    "# Feature Importance\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis', ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Feature Importance Analysis using XGBoost')\n",
    "axs[1, 0].set_xlabel('Importance Score')\n",
    "axs[1, 0].set_ylabel('Features')\n",
    "axs[1, 0].grid()\n",
    "\n",
    "# Displaying Metrics in a Table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "axs[1, 1].axis('tight')\n",
    "axs[1, 1].axis('off')\n",
    "axs[1, 1].table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center')\n",
    "axs[1, 1].set_title('Model Performance Metrics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# SHAP Analysis\n",
    "# Initialize the SHAP explainer with the model and training data\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Summary plot for overall feature importance using SHAP values\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "\n",
    "# Explanation for a single prediction (change the index to check different instances)\n",
    "instance_index = 0  # You can modify this index to examine other instances\n",
    "shap.initjs()  # Initialize JS for interactive plots (useful if in Jupyter)\n",
    "\n",
    "# Waterfall plot to explain why a specific vehicle needs maintenance\n",
    "shap.waterfall_plot(shap_values[instance_index], max_display=10)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4699932,
     "sourceId": 7984545,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
